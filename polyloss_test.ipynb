{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a783474-5cad-43a8-aed6-3d8aefa126c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "174df809-f89d-4d00-b128-de37a3bbb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以确保结果可重复\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c879dced-e328-44a6-b238-788684b35a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成合成数据\n",
    "X, y = make_classification(n_samples=100,    # 总样本数\n",
    "                           n_features=20,     # 特征数\n",
    "                           n_informative=2,   # 有信息的特征数\n",
    "                           n_redundant=10,    # 冗余特征数\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.9, 0.1],# 类别不平衡，90% 类别0，10% 类别1\n",
    "                           flip_y=0,          # 不引入标签噪声\n",
    "                           random_state=42)\n",
    "\n",
    "# 分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "045f6452-9e44-4770-af2d-1642a2af38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 PolyLoss\n",
    "class PolyLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, beta=1, k=3, reduction='mean'):\n",
    "        super(PolyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 计算交叉熵损失\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "        # 计算预测概率\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # PolyLoss 公式\n",
    "        poly_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss + self.beta * (1 - pt) ** self.k\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return poly_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return poly_loss.sum()\n",
    "        else:\n",
    "            return poly_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52d12a91-7b2c-40f9-b13d-539c8843f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的神经网络\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_size=16, num_classes=2):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05d5c7e2-4c99-46bd-afb5-9840dadf4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f91569a-af4b-4677-8c63-df56edaba0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    print(classification_report(all_targets, all_preds, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_targets, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "138a12f9-44de-4ebd-95cd-073f2cec2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5619\n",
      "Epoch [2/10], Loss: 0.5327\n",
      "Epoch [3/10], Loss: 0.5044\n",
      "Epoch [4/10], Loss: 0.4787\n",
      "Epoch [5/10], Loss: 0.4536\n",
      "Epoch [6/10], Loss: 0.4300\n",
      "Epoch [7/10], Loss: 0.4083\n",
      "Epoch [8/10], Loss: 0.3868\n",
      "Epoch [9/10], Loss: 0.3665\n",
      "Epoch [10/10], Loss: 0.3472\n",
      "测试集性能（交叉熵损失）:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    1.0000    0.9474        18\n",
      "           1     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.9000        20\n",
      "   macro avg     0.4500    0.5000    0.4737        20\n",
      "weighted avg     0.8100    0.9000    0.8526        20\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  0]\n",
      " [ 2  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python_etc\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python_etc\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python_etc\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 训练并评估使用普通交叉熵损失的模型\n",
    "model_ce = SimpleNN()\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "optimizer_ce = torch.optim.Adam(model_ce.parameters(), lr=0.001)\n",
    "\n",
    "model_ce = train_model(model_ce, criterion_ce, optimizer_ce, train_loader, num_epochs=10)\n",
    "print(\"测试集性能（交叉熵损失）:\")\n",
    "evaluate_model(model_ce, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78b925a9-3d76-40e1-9cee-b9472463e936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 使用 PolyLoss ===\n",
      "Epoch [1/10], Loss: 0.3351\n",
      "Epoch [2/10], Loss: 0.3062\n",
      "Epoch [3/10], Loss: 0.2798\n",
      "Epoch [4/10], Loss: 0.2541\n",
      "Epoch [5/10], Loss: 0.2309\n",
      "Epoch [6/10], Loss: 0.2081\n",
      "Epoch [7/10], Loss: 0.1881\n",
      "Epoch [8/10], Loss: 0.1691\n",
      "Epoch [9/10], Loss: 0.1528\n",
      "Epoch [10/10], Loss: 0.1377\n",
      "测试集性能（PolyLoss）:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9474    1.0000    0.9730        18\n",
      "           1     1.0000    0.5000    0.6667         2\n",
      "\n",
      "    accuracy                         0.9500        20\n",
      "   macro avg     0.9737    0.7500    0.8198        20\n",
      "weighted avg     0.9526    0.9500    0.9423        20\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  0]\n",
      " [ 1  1]]\n"
     ]
    }
   ],
   "source": [
    "# 训练并评估使用 PolyLoss 的模型\n",
    "print(\"\\n=== 使用 PolyLoss ===\")\n",
    "model_poly = SimpleNN()\n",
    "criterion_poly = PolyLoss(alpha=1, gamma=2, beta=1, k=3)\n",
    "optimizer_poly = torch.optim.Adam(model_poly.parameters(), lr=0.001)\n",
    "\n",
    "model_poly = train_model(model_poly, criterion_poly, optimizer_poly, train_loader, num_epochs=10)\n",
    "print(\"测试集性能（PolyLoss）:\")\n",
    "evaluate_model(model_poly, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24007e62-e0b5-4be7-b52d-924830adcec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
